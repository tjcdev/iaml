{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Instructions\n",
    "\n",
    "**It is important that you follow the instructions below to the letter - we will not be responsible for incorrect marking due to non-standard practices.**\n",
    "\n",
    "1. You *MUST* have your environment set up as in the [README](https://github.com/michael-camilleri/IAML2018) and you *must activate this environment before running this notebook*:\n",
    "```\n",
    "source activate py3iaml\n",
    "cd [DIRECTORY CONTAINING GIT REPOSITORY]\n",
    "jupyter notebook\n",
    "# Navigate to this file\n",
    "```\n",
    "\n",
    "1. Read the instructions carefully, especially where asked to name variables with a specific name. Wherever you are required to produce code you should use code cells, otherwise you should use markdown cells to report results and explain answers. In most cases we indicate the nature of answer we are expecting (code/text), and also provide the code/markdown cell where to put it\n",
    "\n",
    "1. There are some questions which are **specific to those taking the Level-11 version** of the course (INFR11182 and INFR11152). These are clearly marked with the words **(LEVEL 11)** and must be completed by those taking the Level 11 course. Those on the Level 10 version (INFR10069) may (and are advised to) attempt such questions but this will not affect their mark in any way, nor will they get feedback on them.\n",
    "\n",
    "1. The .csv files that you will be using are located at `./datasets` (i.e. use the `datasets` directory **adjacent** to this file).\n",
    "\n",
    "1. Keep your answers brief and concise. Most written questions can be answered with 2-3 lines of explanation.\n",
    "\n",
    "1. Make sure to show **all** your code/working. \n",
    "\n",
    "1. Write readable code. While we do not expect you to follow [PEP8](https://www.python.org/dev/peps/pep-0008/) to the letter, the code should be adequately understandable, with plots/visualisations correctly labelled. **Do** use inline comments when doing something non-standard. When asked to present numerical values, make sure to represent real numbers in the appropriate precision to exemplify your answer. Marks *WILL* be deducted if the marker cannot understand your logic/results.\n",
    "\n",
    "1. **Collaboration:** You may discuss the assignment with your colleagues, provided that the writing that you submit is entirely your own. That is, you should NOT borrow actual text or code from other students. We ask that you provide a list of the people who you've had discussions with (if any).\n",
    "\n",
    "### SUBMISSION Mechanics\n",
    "\n",
    "**IMPORTANT:** You must submit this assignment by **Thursday 18/10/2018 at 16:00**. \n",
    "\n",
    "**Late submissions:** The policy stated in the School of Informatics is that normally you will not be allowed to submit coursework late. See the [ITO webpage](http://web.inf.ed.ac.uk/infweb/student-services/ito/admin/coursework-projects/late-coursework-extension-requests) for exceptions to this, e.g. in case of serious medical illness or serious personal problems.\n",
    "\n",
    "**Resubmission:** If you submit your file again, the previous submission is **overwritten**. We will mark the version that is in the submission folder at the deadline.\n",
    "\n",
    "All submissions happen electronically. To submit:\n",
    "\n",
    "1. Fill out this notebook, and save it, making sure to **KEEP the name of the file UNCHANGED**.\n",
    "\n",
    "1. On a DICE environment, open the terminal, navigate to the location of this notebook, and submit this notebook file using the following command:\n",
    "\n",
    "  ```submit iaml cw1 \"02_LinearRegression.ipynb\"```\n",
    "\n",
    "  What actually happens in the background is that your file is placed in a folder available to markers. If you submit a file with the same name into the same location, **it will *overwrite* your previous submission**. You can check the status of your submissions with the `show_submissions` command.\n",
    "  \n",
    "1. **Distance Learners:** To copy your work onto DICE (so that you can use the `submit` command) you can use `scp` or `rsync` (you may need to install these yourself). You can copy files to `student.ssh.inf.ed.ac.uk`, then ssh into it in order to submit. The following is an example (replace entries in `[square brackets]` with your specific details):\n",
    "```\n",
    "filename=\"02_LinearRegression.ipynb\"\n",
    "local_scp_filepath=[DIRECTORY CONTAINING GIT REPOSITORY]${filename}\n",
    "server_address=student.ssh.inf.ed.ac.uk\n",
    "scp -r ${local_scp_filepath} [YOUR USERNAME]@${server_address}:${filename}\n",
    "# rsync -rl ${local_scp_filepath} [YOUR USERNAME]@${server_address}:${filename}\n",
    "ssh [YOUR USERNAME]@${server_address}\n",
    "ssh student.login\n",
    "submit iaml cw1 \"02_LinearRegression.ipynb\"\n",
    "```\n",
    "\n",
    "**N.B.: This is still Coursework 1 (cw1)**\n",
    "\n",
    "### Marking Breakdown\n",
    "\n",
    "The Level 10 and Level 11 points are marked out of different totals, however these are all normalised to 100%.\n",
    "\n",
    "**70-100%** results/answer correct plus extra achievement at understanding or analysis of results. Clear explanations, evidence of creative or deeper thought will contribute to a higher grade.\n",
    "\n",
    "**60-69%** results/answer correct or nearly correct and well explained.\n",
    "\n",
    "**50-59%** results/answer in right direction but significant errors.\n",
    "\n",
    "**40-49%** some evidence that the student has gained some understanding, but not answered the questions\n",
    "properly.\n",
    "\n",
    "**0-39%** serious error or slack work.\n",
    "\n",
    "Note that while this is not a programming assignment, in questions which involve visualisation of results and/or long cold snippets, some marks may be deducted if the code is not adequately readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Execute the cell below to import all packages you will be using in the rest of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice Formatting within Jupyter Notebook\n",
    "%matplotlib inline\n",
    "from IPython.display import display # Allows multiple displays from a single code-cell\n",
    "\n",
    "# System functionality\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import Here any Additional modules you use. To import utilities we provide, use something like:\n",
    "#   from utils.plotter import plot_hinton\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils.plotter import scatter_jitter, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the dataset\n",
    "This assignment is based on the automobile pricing dataset. Our goal will be to predict the price of automobiles based on various attributes. This data set consists of three types of entities: \n",
    "\n",
    "1. The specification of an automobile in terms of various characteristics \n",
    "\n",
    "1. Assigned insurance risk rating \n",
    "   * this rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuaries call this process ”symboling”. A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe. \n",
    "\n",
    "1. Normalized losses in use as compared to other cars\n",
    "  * the third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year (avg_loss/car/year). \n",
    "\n",
    "\n",
    "To save you time and to make the problem manageable with limited computational resources, we preprocessed the original dataset. We removed any instances that had one or more missing values and randomized the data set. The resulting representation is much more compact and can be used directly to perform our experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Visualisation\n",
    "\n",
    "Before jumping into our problem, it is beneficial to get a feel for the data we are dealing with in the rest of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='question_1_1'></a>\n",
    "### ========== Question 1.1 --- [8 marks] ==========\n",
    "\n",
    "Load the dataset `train_auto_numeric.csv` into a pandas DataFrame called `auto_numeric`. Using any suitable pandas functionality, \n",
    "1. [Code] summarise *and*\n",
    "1. [Text] comment upon\n",
    "\n",
    "the key features of the data. Show all your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>engine-power</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>mean-effective-pressure</th>\n",
       "      <th>torque</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>121.955975</td>\n",
       "      <td>98.559748</td>\n",
       "      <td>171.698113</td>\n",
       "      <td>65.729560</td>\n",
       "      <td>53.925157</td>\n",
       "      <td>14.056352</td>\n",
       "      <td>3.294528</td>\n",
       "      <td>3.219874</td>\n",
       "      <td>10.446855</td>\n",
       "      <td>98528.301887</td>\n",
       "      <td>5072.012579</td>\n",
       "      <td>27.113208</td>\n",
       "      <td>32.327044</td>\n",
       "      <td>46.180503</td>\n",
       "      <td>200.055031</td>\n",
       "      <td>11684.723270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.434186</td>\n",
       "      <td>5.803361</td>\n",
       "      <td>12.656791</td>\n",
       "      <td>2.292021</td>\n",
       "      <td>2.410446</td>\n",
       "      <td>17.143568</td>\n",
       "      <td>0.296959</td>\n",
       "      <td>0.381833</td>\n",
       "      <td>4.414796</td>\n",
       "      <td>34123.715967</td>\n",
       "      <td>549.988239</td>\n",
       "      <td>7.848229</td>\n",
       "      <td>8.231998</td>\n",
       "      <td>28.780966</td>\n",
       "      <td>513.289289</td>\n",
       "      <td>6744.910579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>86.600000</td>\n",
       "      <td>141.100000</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>3.390000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>5118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>163.400000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>6.960000</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>69000.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>21.775000</td>\n",
       "      <td>34.140000</td>\n",
       "      <td>7372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>171.700000</td>\n",
       "      <td>65.400000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>9.030000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>92000.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>55.900000</td>\n",
       "      <td>9233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>145.000000</td>\n",
       "      <td>101.200000</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>14.885000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>116000.000000</td>\n",
       "      <td>5450.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>68.495000</td>\n",
       "      <td>119.990000</td>\n",
       "      <td>14719.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>256.000000</td>\n",
       "      <td>115.600000</td>\n",
       "      <td>202.600000</td>\n",
       "      <td>71.700000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>174.160000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>99.850000</td>\n",
       "      <td>3912.870000</td>\n",
       "      <td>42056.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized-losses  wheel-base      length       width      height  \\\n",
       "count         159.000000  159.000000  159.000000  159.000000  159.000000   \n",
       "mean          121.955975   98.559748  171.698113   65.729560   53.925157   \n",
       "std            39.434186    5.803361   12.656791    2.292021    2.410446   \n",
       "min            65.000000   86.600000  141.100000   60.300000   49.400000   \n",
       "25%            93.000000   94.500000  163.400000   64.000000   52.000000   \n",
       "50%           110.000000   97.000000  171.700000   65.400000   54.100000   \n",
       "75%           145.000000  101.200000  177.800000   66.500000   55.600000   \n",
       "max           256.000000  115.600000  202.600000   71.700000   59.800000   \n",
       "\n",
       "       engine-size        bore      stroke  compression-ratio   engine-power  \\\n",
       "count   159.000000  159.000000  159.000000         159.000000     159.000000   \n",
       "mean     14.056352    3.294528    3.219874          10.446855   98528.301887   \n",
       "std      17.143568    0.296959    0.381833           4.414796   34123.715967   \n",
       "min       3.390000    2.540000    2.070000           7.000000   48000.000000   \n",
       "25%       6.960000    3.050000    3.070000           8.600000   69000.000000   \n",
       "50%       9.030000    3.270000    3.270000           9.000000   92000.000000   \n",
       "75%      14.885000    3.580000    3.410000           9.400000  116000.000000   \n",
       "max     174.160000    3.940000    4.170000          23.000000  200000.000000   \n",
       "\n",
       "          peak-rpm    city-mpg  highway-mpg  mean-effective-pressure  \\\n",
       "count   159.000000  159.000000   159.000000               159.000000   \n",
       "mean   5072.012579   27.113208    32.327044                46.180503   \n",
       "std     549.988239    7.848229     8.231998                28.780966   \n",
       "min    4150.000000   15.000000    18.000000                 0.490000   \n",
       "25%    4800.000000   22.000000    26.500000                21.775000   \n",
       "50%    5100.000000   26.000000    32.000000                49.800000   \n",
       "75%    5450.000000   31.000000    37.000000                68.495000   \n",
       "max    6600.000000   49.000000    54.000000                99.850000   \n",
       "\n",
       "            torque         price  \n",
       "count   159.000000    159.000000  \n",
       "mean    200.055031  11684.723270  \n",
       "std     513.289289   6744.910579  \n",
       "min      19.400000   5118.000000  \n",
       "25%      34.140000   7372.000000  \n",
       "50%      55.900000   9233.000000  \n",
       "75%     119.990000  14719.500000  \n",
       "max    3912.870000  42056.000000  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1)\n",
    "# Load data from csv\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'train_auto_numeric.csv')\n",
    "auto_numeric = pd.read_csv(data_path, delimiter = ',')\n",
    "\n",
    "auto_numeric.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalized-losses           51\n",
       "wheel-base                  40\n",
       "length                      56\n",
       "width                       33\n",
       "height                      39\n",
       "engine-size                 32\n",
       "bore                        33\n",
       "stroke                      31\n",
       "compression-ratio           29\n",
       "engine-power                48\n",
       "peak-rpm                    20\n",
       "city-mpg                    25\n",
       "highway-mpg                 28\n",
       "mean-effective-pressure    157\n",
       "torque                     158\n",
       "price                      145\n",
       "dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate potential categorical attributes\n",
    "auto_numeric.apply(lambda x: len(np.unique(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 16)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>engine-power</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>mean-effective-pressure</th>\n",
       "      <th>torque</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>8.85</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102000.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.52</td>\n",
       "      <td>57.68</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>162.4</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>15.18</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.39</td>\n",
       "      <td>59.59</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158.0</td>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>51.6</td>\n",
       "      <td>15.18</td>\n",
       "      <td>3.94</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3344.79</td>\n",
       "      <td>17710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>158.7</td>\n",
       "      <td>67.7</td>\n",
       "      <td>55.9</td>\n",
       "      <td>13.74</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.74</td>\n",
       "      <td>68.97</td>\n",
       "      <td>23875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>176.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>8.67</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.78</td>\n",
       "      <td>53.48</td>\n",
       "      <td>16430.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   normalized-losses  wheel-base  length  width  height  engine-size  bore  \\\n",
       "0              164.0        99.8   176.6   66.2    54.3         8.85  3.19   \n",
       "1              110.0        99.4   162.4   66.4    54.3        15.18  3.19   \n",
       "2              158.0       105.8   192.7   71.4    51.6        15.18  3.94   \n",
       "3              106.0        86.6   158.7   67.7    55.9        13.74  3.13   \n",
       "4              192.0       101.2   176.8   64.8    54.3         8.67  3.50   \n",
       "\n",
       "   stroke  compression-ratio  engine-power  peak-rpm  city-mpg  highway-mpg  \\\n",
       "0     3.4               10.0      102000.0    5500.0      24.0         30.0   \n",
       "1     3.4                8.0      115000.0    5500.0      18.0         22.0   \n",
       "2     2.8                8.5       70000.0    4400.0      28.0         30.0   \n",
       "3     3.5                7.8      140000.0    5600.0      32.0         20.0   \n",
       "4     2.8                8.8      101000.0    5800.0      23.0         29.0   \n",
       "\n",
       "   mean-effective-pressure   torque    price  \n",
       "0                    40.52    57.68  13950.0  \n",
       "1                    47.39    59.59  17450.0  \n",
       "2                     0.85  3344.79  17710.0  \n",
       "3                    44.74    68.97  23875.0  \n",
       "4                    44.78    53.48  16430.0  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) \n",
    "\n",
    "- The dataset has 16 attributes and instances datapoints. \n",
    "- Every attribute appears to be numeric\n",
    "- There appears to be a big difference in the magnitude of attribute values e.g. the mean of 'bore' is ~3 and the mean of engine-power is ~100,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 --- [18 marks] ==========\n",
    "\n",
    "We will now examine the attributes in some detail. Familiarise yourself with the concept of Correlation Coefficients (start from the Lecture on Generalisation and Evaluation).\n",
    "\n",
    "1. [Code] Analyse first the relationship between each attribute and price:\n",
    "  1. Compute the correlation coefficient between each attribute and price, *and*\n",
    "  1. Visualise the (pairwise) distribution of each attribute with price\n",
    "1. [Text] Given the above, which attributes do you feel may be most useful in predicting the price? (mention at least 5). How did you reach this conclusion? *Hint: which is the more useful of the above tools?*\n",
    "1. [Code] Now we will analyse the relationship between the attributes themselves. Use an appropriate pairwise visualisation tool to display graphically the relationship between each pair of attributes you selected in (2).\n",
    "1. [Text] Do any attributes exhibit significant correlations between one-another? (restrict your analysis to useful attributes identified above)\n",
    "1. [Text] Which attributes (give examples) would you consider removing if we wish to reduce the dimensionality of the problem and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr</th>\n",
       "      <th>correlation_coefficient</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>engine-size</td>\n",
       "      <td>0.715125</td>\n",
       "      <td>0.715125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>width</td>\n",
       "      <td>0.524326</td>\n",
       "      <td>0.524326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>length</td>\n",
       "      <td>0.512883</td>\n",
       "      <td>0.512883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>engine-power</td>\n",
       "      <td>0.443969</td>\n",
       "      <td>0.443969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>highway-mpg</td>\n",
       "      <td>-0.438467</td>\n",
       "      <td>0.438467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wheel-base</td>\n",
       "      <td>0.423511</td>\n",
       "      <td>0.423511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bore</td>\n",
       "      <td>0.365207</td>\n",
       "      <td>0.365207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>city-mpg</td>\n",
       "      <td>-0.356790</td>\n",
       "      <td>0.356790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>height</td>\n",
       "      <td>0.139563</td>\n",
       "      <td>0.139563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stroke</td>\n",
       "      <td>0.127834</td>\n",
       "      <td>0.127834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>compression-ratio</td>\n",
       "      <td>0.125683</td>\n",
       "      <td>0.125683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mean-effective-pressure</td>\n",
       "      <td>-0.104860</td>\n",
       "      <td>0.104860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>torque</td>\n",
       "      <td>0.101435</td>\n",
       "      <td>0.101435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>peak-rpm</td>\n",
       "      <td>-0.099345</td>\n",
       "      <td>0.099345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normalized-losses</td>\n",
       "      <td>0.015368</td>\n",
       "      <td>0.015368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       attr  correlation_coefficient       abs\n",
       "5               engine-size                 0.715125  0.715125\n",
       "3                     width                 0.524326  0.524326\n",
       "2                    length                 0.512883  0.512883\n",
       "9              engine-power                 0.443969  0.443969\n",
       "12              highway-mpg                -0.438467  0.438467\n",
       "1                wheel-base                 0.423511  0.423511\n",
       "6                      bore                 0.365207  0.365207\n",
       "11                 city-mpg                -0.356790  0.356790\n",
       "4                    height                 0.139563  0.139563\n",
       "7                    stroke                 0.127834  0.127834\n",
       "8         compression-ratio                 0.125683  0.125683\n",
       "13  mean-effective-pressure                -0.104860  0.104860\n",
       "14                   torque                 0.101435  0.101435\n",
       "10                 peak-rpm                -0.099345  0.099345\n",
       "0         normalized-losses                 0.015368  0.015368"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) A.\n",
    "# Calculate the correlation coefficients and store them in a numpy array\n",
    "prices = auto_numeric['price']\n",
    "attributes = auto_numeric.drop(columns=['price'])\n",
    "corrs = np.array([prices.corr(auto_numeric[attr]) for attr in attributes])\n",
    "\n",
    "# Store these coefficients in a pandas dataframe\n",
    "corrs_series = {'attr': auto_numeric.drop(columns=['price']).columns, 'correlation_coefficient': corrs}\n",
    "corrs = pd.DataFrame(data=corrs_series)\n",
    "\n",
    "# Now order the attributes by the correlation coeffiencts absolute value\n",
    "corrs['abs'] = abs(corrs['correlation_coefficient'])\n",
    "corrs.sort_values(by='abs', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. \n",
    "sns.pairplot(data=auto_numeric, x_vars=auto_numeric.drop(columns=['price']).columns[:5], y_vars=['price'])\n",
    "sns.pairplot(data=auto_numeric, x_vars=auto_numeric.drop(columns=['price']).columns[5:10], y_vars=['price'])\n",
    "sns.pairplot(data=auto_numeric, x_vars=auto_numeric.drop(columns=['price']).columns[10:15], y_vars=['price'])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)\n",
    "1. engine-size\n",
    "2. width\n",
    "3. length\n",
    "4. engine-power\n",
    "5. wheel-base\n",
    "\n",
    "I reached this conclusion because they are highly correlated to price. The most useful tools was pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3)\n",
    "sns.pairplot(auto_numeric, vars=[\"engine-size\", \"width\", \"length\", \"engine-power\", \"wheel-base\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) From the above plot we can see that \n",
    "  * engine-power and length\n",
    "  * length and wheel base\n",
    "  * wheel-base and width\n",
    "  \n",
    "all appear to correlate with eachother"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) height, stroke, compression-ratio, mean-effective-pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Linear Regression\n",
    "\n",
    "When applying machine learning in practice it can be prudent to start out simple in order to get a feeling for the dataset and for any potential difficulties that might warrant a more sophisticated model. We will thus begin by studying a simple Linear Regression model. Such a model will consider the relationship between a dependent (response) variable and only one independent (explanatory) variable, which we take to be the `engine-power`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 --- [5 marks] ==========\n",
    "\n",
    "1. [Code] Produce a scatter plot of `price` against `engine-power` (label the axis). \n",
    "1. [Text] What are your thoughts about the ability of the variable to predict the price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "scatter_jitter(auto_numeric['price'], auto_numeric['engine-power'])\n",
    "plt.xlabel('price')\n",
    "plt.ylabel('engine-power')\n",
    "plt.title(\"Price vs Engine Power\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) It is going to be very difficult to use engine-power as a predictor of price. There appears to maybe be a vague correlation but there the scatter is still quite spread out with several outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 --- [8 marks] ==========\n",
    "\n",
    "1. [Code] Now visualise the distribution of the car price (again label the axes). Choose a sensible value for the number of bins in the histogram.\n",
    "1. [Text] Comment on why the price variable *may not* be easy to model using linear regression, and suggest possible preprocessing to improve its applicability. At the same time, explain why it is not conclusive that it is the case at this stage. \n",
    "*N.B. There is no need to carry out the preprocessing at this stage, just comments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "auto_numeric['price'].hist(bins=15)\n",
    "plt.title(\"Distribution of Prices\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) \n",
    "\n",
    "This may not be easy to model using Linear Regression because,\n",
    "- There appear to be a number of outliers whichinear regression is known to be sensitive to.\n",
    "- The histogram plot also suggests that the distribution of price is not a gaussian distribution. \n",
    "\n",
    "Preprocessing could include:\n",
    "- Removing outliers\n",
    "- Normalising the data\n",
    "- Applying a basis function to the price attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 --- [3 marks] ==========\n",
    "We want to prepare our dataset for training/testing. Extract the dependent variable into a vector and the independent attribute into another. Split the dataset with 80% for training and the remaining 20% for testing, naming the resulting arrays `X_train`, `X_test`, `y_train` and `y_test`.\n",
    "\n",
    "*Hint: you may use Scikit's `train_test_split`: set the random state to 0 for reproducibility*.\n",
    "\n",
    "**N.B. For technical reasons, `X_train`/`X_test` must be 2D arrays: extend the dimensions of the independent attribute before splitting the dataset, such that the shape of the resulting array is (n,1) where n is the number of instances in the dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(auto_numeric['engine-power'], axis=1)\n",
    "y = np.expand_dims(auto_numeric['price'], axis=1)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 --- [4 marks] ==========\n",
    "\n",
    "Decide on a simple **baseline** to predict the `price` variable. Implement it and display its parameter.\n",
    "\n",
    "*Hint: This should be just 1 line of code + a print/display*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The baseline will be the line y = average price\n",
    "def baseline_predict(X):\n",
    "    return np.mean(y_train)\n",
    "\n",
    "print(np.around(baseline_predict(X_train), decimals=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='question_2_5'></a>\n",
    "### ========== Question 2.5 --- [7 marks] ==========\n",
    "Now we want to build a simple linear regression model. We will use Scikit-learn's [`LinearRegression`](http://scikit-learn.org/0.19/modules/generated/sklearn.linear_model.LinearRegression.html) class. \n",
    "1. [Code] Train a `LinearRegression` model and report its parameters: ***N.B.*** *Here we mean the weights of the Regression  Function*.\n",
    "1. [Text] Interpret the result, and comment on what impact this has *if any* on the relevance of the `engine-power` attribute to predict the `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "# Train a linear regression model on the training set\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "# Report the model parameters.\n",
    "print(\"The gradient of the line: \" + str(np.around(lr.coef_[0], decimals=4)))\n",
    "print(\"The intercept of the line: \" + str(np.around(lr.intercept_, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) \n",
    "\n",
    "- The gradient is positive and so this shows us that as the engine-power increases, the price will also increase.\n",
    "- The gradient is also quite low which also shows that an increase in engine-power results in a small increase in price\n",
    "- In this example the intercept is fairly meaningless but it tells us that a car without any engine-power is worth $2823"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 --- [9 marks] ==========\n",
    "Now we will evaluate and compare the performance of our models on the **testing** data.\n",
    "1. [Code] Produce a scatter plot of the *test-data* price data-points (i.e. plot the independent variable along the X-axis and the price along the Y-axis). Add the regression line to the plot and show the predictions on the testing set by using a different marker. Finally plot also the baseline predictor (same figure). Label your axes and provide a [legend](https://matplotlib.org/2.2.3/api/legend_api.html).\n",
    "1. [Text] Just by looking at this plot, how do the two models compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the test data\n",
    "plot_test = ax.scatter(X_test, y_test, c='blue', label='Test Data')\n",
    "\n",
    "# Plot the linear regression model predictions on the test data\n",
    "plot_pred = ax.scatter(X_test, lr.predict(X_test), c='red', label='Predicted Data')\n",
    "\n",
    "# Calculate regression fit line and plot it\n",
    "x_vals = np.expand_dims(ax.get_xlim(), axis=1)\n",
    "y_vals = lr.intercept_ + lr.coef_ * x_vals\n",
    "plot_lr, = ax.plot(x_vals, y_vals, '--', c='green', label='Regression Model')\n",
    "\n",
    "# Plot the baseline\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = np.array([baseline_predict(x) for x in x_vals])\n",
    "plot_baseline, = ax.plot(x_vals, y_vals, '-', c='black', label='Baseline')\n",
    "\n",
    "# Add legend\n",
    "ax.legend(handles=[plot_test, plot_pred, plot_lr, plot_baseline])\n",
    "\n",
    "# Set the x and y labels\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_xlabel('Engine Power')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) For lower values of Engine Power (<100,000) the linear regression model is clearly better at predicting price. However as the engine power increase the baseline and regression model probably acheive comparable accuracy since the spread of points becomes wider as engine power values increase above 100,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 --- [20 marks] ==========\n",
    " \n",
    "You might have noticed that the above plot is not easy to interpret. \n",
    "1. [Code] Generate another plot, this time showing a histogram of the residuals under both models (label everything). \n",
    "1. [Code] Report also the Coefficient of Determination ($R^2$) and Root Mean Squared Error (RMSE) on the same **hold-out** testing set for both predictors. *Hint: Scikit Learn has functions to help in evaluating both measures.*\n",
    "1. [Text] Comment on the result. *Hint: In your answer, you should discuss what the graph is showing and what the two values are measuring, and finally compare the two models under all measures/plots.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "num_bins = 20\n",
    "\n",
    "# Get linear regression predictions\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# Get baseline predictions\n",
    "baseline_pred = np.array([baseline_predict(x) for x in X_test])\n",
    "\n",
    "# Plot histograms of residuals\n",
    "lr_residuals = sns.distplot((y_test - lr_pred), label='Linear Regression Model', bins=num_bins, kde=False)\n",
    "baseline_residuals = sns.distplot((y_test - baseline_predict(X_test)), label='Baseline Model', bins=num_bins, kde=False)\n",
    "\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency of Residual\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "r2 = r2_score(y_test, lr_pred)\n",
    "mse = mean_squared_error(y_test, lr_pred)\n",
    "print(\"Coefficient of Determination: \" + str(np.around(r2, decimals=4)))\n",
    "print(\"Root Mean Squared Error (RMSE): \" + str(np.around(mse, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, baseline_pred)\n",
    "mse = mean_squared_error(y_test, baseline_pred)\n",
    "print(\"Coefficient of Determination: \" + str(np.around(r2, decimals=4)))\n",
    "print(\"Root Mean Squared Error (RMSE): \" + str(np.around(mse, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)\n",
    "\n",
    "- The residuals show us what the error is on each data point for each model. And so this histogram shows us what the residuals were and any patterns in them, for example how many times did the linear regression model underestimate the actual price by ~$5000. \n",
    "\n",
    "- We can see from our histogram that the baseline model is under estimating the value of price by a large margin and more frequently than the linear regression model. The linear regression model has the majority of it's residuals close to 0, whereas the baseline model has the majority of it's residuals clustered aroun -$5000.\n",
    "- The coefficient of determination tells us how close the actual data points are to our line fitted by our models. A higher coefficient of determination is better and we can therefore see that our linear regression model is performing better.\n",
    "- The Root Mean Squared Error (RMSE) is the standard deviation of the residuals and it, roughly speaking, tells you how close the actual data points are to our line. A lower value is better and we can therefore see that our linear regression model is performing better than the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='question_2_8'></a>\n",
    "### ========== Question 2.8 --- [9 marks] ==========\n",
    "\n",
    "So far we have used a hold-out test set for validation.\n",
    "\n",
    "1. [Text] What are the repurcussions of this for interpreting the above results?\n",
    "\n",
    "1. [Code] To solve this problem, we will use k-fold cross-validation to evaluate the performance of the regression model. By using Scikit-learn's [`KFold`](http://scikit-learn.org/0.19/modules/generated/sklearn.model_selection.KFold.html) class construct a 5-fold cross-validation object. Set `shuffle=True` and `random_state=0`. ***[Optional]*** *You may wish to visualise the training/validation indices per fold. The `split` method comes in handy in this case.*\n",
    "\n",
    "  **N.B. You will use this KFold instance you are about to create throughout most of the remainder of this Assignment - keep track of it!**\n",
    "\n",
    "1. [Code] Then train a new Linear Regression Model using the [`cross_val_predict`](http://scikit-learn.org/0.19/modules/generated/sklearn.model_selection.cross_val_predict.html) function. Report the Coefficient of Determination ($R^2$) and Root Mean Squared Error (RMSE).\n",
    "\n",
    "1. [Text] Relate these to the previous results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) By using our test set for validation we have, in essence, performed some training on the test set and so we no longer have a set that we can use to estimate the generalisation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "# Create 5-fold cross-validation object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Visualise the splits on the dataset\n",
    "for train_idx, test_idx in kf.split(auto_numeric):\n",
    "    print(\"Training set indices: \" + str(train_idx))\n",
    "    print(\"Testing set indices: \" + str(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3)\n",
    "# Create a new linear regression model and train it using kfold cross validation\n",
    "lr = LinearRegression()\n",
    "y_pred = cross_val_predict(lr, np.expand_dims(auto_numeric['engine-power'], axis=1), auto_numeric['price'], cv=kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model Trained using K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(auto_numeric['price'], y_pred)\n",
    "mse = mean_squared_error(auto_numeric['price'], y_pred)\n",
    "print(\"Coefficient of Determination: \" + str(np.around(r2, decimals=4)))\n",
    "print(\"Root Mean Squared Error (RMSE): \" + str(np.around(mse, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) This model performed marginally better than the linear regression model trained in 2.7, we can see this since the coefficient of determination is slightly higher and the RMSE is slightly lower. This suggests that using KFold cross validation was beneficial for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 --- (LEVEL 11) --- [18 marks] ==========\n",
    "\n",
    "1. [Code] Load the new dataset `train_auto_base.csv` into a pandas DataFrame `auto_base`. Again by using the `engine-power` attribute as predictor and `price` as target variable build a LinearRegression model on this dataset. Report the $R^2$ and RMSE metrics for this model (on testing set). \n",
    "\n",
    "1. [Code/Text] You should notice a significant change in performance. Where is this coming from? Use visualisation/analysis methods you have learnt to answer this question. Document your code and describe your analysis (via inline comments) as you progress. Your written answer should be just a short paragraph (1-3 sentences) describing your conclusion.\n",
    "\n",
    "*Hint: you may find it easier to understand what is happening if you use a hold-out test-set rather than cross-validation in this case. Also, make use of pandas methods to help you.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'train_auto_base.csv')\n",
    "auto_base = pd.read_csv(data_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a linear regression model on the auto_base dataset\n",
    "lr = LinearRegression()\n",
    "lr.fit(np.expand_dims(auto_base['engine-power'], axis=1), auto_base['price'])\n",
    "y_pred = lr.predict(np.expand_dims(auto_base['engine-power'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model Training on Auto-Base Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(auto_base['price'], y_pred)\n",
    "mse = mean_squared_error(auto_base['price'], y_pred)\n",
    "print(\"Coefficient of Determination: \" + str(np.around(r2, decimals=4)))\n",
    "print(\"Root Mean Squared Error (RMSE): \" + str(np.around(mse, decimals=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "# Produce a scatter plot of price vs. engine-power\n",
    "scatter_jitter(auto_base['price'], auto_base['engine-power'])\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Engine Power')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print coefficients of linear regression fit\n",
    "print(lr.coef_)\n",
    "print(np.around(lr.intercept_, decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a summary of the data\n",
    "auto_base.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first 10 items\n",
    "auto_base[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) - Final Conclusion(s)\n",
    "\n",
    "- Every row in this dataset has the same value of engine power. This results in a model that just predicts the mean of the prices everytime, producing an innacurate model.\n",
    "- You can use the engine power as a predictor because we don't know what happens to price when engine power changes, because we don't have any example with which to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multivariate Linear Regression\n",
    "In this Section we will fit a Multivariate Linear Regression model (still using [`LinearRegression`](http://scikit-learn.org/0.19/modules/generated/sklearn.linear_model.LinearRegression.html)) to the dataset: i.e. we will now train a model with **multiple** explanatory variables and ascertain how they affect our ability to predict the retail price of a car. \n",
    "\n",
    "**N.B. We will use the *KFold* instance you created in [Question 2.8](#question_2_8) to train & validate our models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.1 --- [6 marks] ==========\n",
    "\n",
    "1. [Code] Train a Multi-Variate `LinearRegression` model on the original `auto_numeric` dataframe you loaded in [Question 1.1](#question_1_1), and evaluate it using the *KFold* instance you created in [Question 2.8](#question_2_8) (report RMSE and $R^2$). \n",
    "1. [Text] Comment on the result, and compare with the univariate linear regression model we trained previously ([Question 2.5](#question_2_5))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "# Create and filt our linear regression model\n",
    "mvlr = LinearRegression()\n",
    "mvlr.fit(auto_numeric.drop(columns=['price']), auto_numeric['price'])\n",
    "\n",
    "# Evaluate it using our KFold instance\n",
    "y_pred = cross_val_predict(mvlr, auto_numeric.drop(columns=['price']), auto_numeric['price'], cv=kf)\n",
    "\n",
    "\n",
    "r2 = r2_score(auto_numeric['price'], y_pred)\n",
    "mse = mean_squared_error(auto_numeric['price'], y_pred)\n",
    "# Evaluate our model \n",
    "print(\"Coefficient of Determination: \" + str(np.around(r2, decimals=4)))\n",
    "print(\"Root Mean Squared Error (RMSE): \" + str(np.around(mse, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) \n",
    "- We can clearly see that the cross valdiation method on auto_numeric has resulted in a less accurate model. The coefficient of determination is significantly lower and then RMSE is significantly higher indicating a model that does not fit the data well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.2 --- [4 marks] ==========\n",
    "\n",
    "1. [Code] Examine the scatter plot of `engine-size` vs `price` (plot below)\n",
    "1. [Text] Why might this cause a problem for linear regression? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "# Plot this as a scatter plot against the price attribute\n",
    "ax = sns.scatterplot(auto_numeric['engine-size'], auto_numeric['price'])\n",
    "ax.set_xlabel('Engine-size')\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_title('Price vs. Engine-size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) \n",
    "\n",
    "- There appear to be outliers in the dataset and linear regression is known to not handle outliers well.\n",
    "- Inspecting the distribution on the graph suggests that the relationship between engine-size and price is not linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='question_3_3'></a>\n",
    "### ========== Question 3.3 --- [10 marks] ==========\n",
    "In class we discussed ways of preprocessing features to improve performance in such cases.\n",
    "1. [Code] Transform the `engine-size` attribute using an appropriate technique from the lectures (document it in your code) and show the transformed data (scatter plot).\n",
    "1. [Code] Then retrain a (Multi-variate) LinearRegression Model (on all the attributes including the transformed `engine-size`) and report $R^2$ and RMSE. \n",
    "1. [Text] How has the performance of the model changed when compared to the previous result? and why so significantly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "# The original scatter plot appears to show an exponential distribution \n",
    "# therefore we are going to take the logarithm of the engine-size attribute\n",
    "\n",
    "# Take log of the engine-size attribute\n",
    "log_engine_size = np.log(auto_numeric['engine-size'])\n",
    "\n",
    "# Plot this as a scatter plot against the price attribute\n",
    "ax = sns.scatterplot(log_engine_size, auto_numeric['price'])\n",
    "ax.set_xlabel('log(Engine-size)')\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_title('Price vs. log(Engine-size)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "mvlr_log = LinearRegression()\n",
    "\n",
    "# Replace the original engine-size attribute with the log(engine-size)\n",
    "auto_numeric['engine-size'] = log_engine_size\n",
    "\n",
    "# Fit the new linear regression model\n",
    "mvlr_log.fit(auto_numeric.drop(columns=['price']), auto_numeric['price'])\n",
    "\n",
    "# Make predictions for the prices\n",
    "y_pred = cross_val_predict(mvlr_log, auto_numeric.drop(columns=['price']), auto_numeric['price'], cv=kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model with Log of the Engine-Size Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(auto_numeric['price'], y_pred)\n",
    "mse = mean_squared_error(auto_numeric['price'], y_pred)\n",
    "print(\"Coefficient of Determination (R^2): \" + str(np.around(r2, decimals=4)))\n",
    "print(\"Root Mean Squared Error (RMSE): \" + str(np.around(mse, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is not significantly better, this is most likely due to the preprocessed engine-size attribute now being a good indicator of price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.4 --- (LEVEL 11) --- [12 marks] ==========\n",
    "\n",
    "The simplicity of Linear Regression allows us to interpret the importance of certain features in predicting target variables. However this is not as straightforward as just reading off the coefficients of each of the attributes and ranking them in order of magnitude.\n",
    "\n",
    "1. [Text] Why is this? How can we *linearly* preprocess the attributes to allow for a comparison? Justify your answer.\n",
    "1. [Code] Perform the preprocessing you just mentioned on the transformed data-set from [Question 3.3](#question_3_3), retrain the Linear-Regressor and report the coefficients in a readable manner. *Tip: To simplify matters, you may abuse standard practice and train the model once on the entire data-set with no validation/test set.*\n",
    "1. [Text] Which are the three (3) most important features for predicting price under this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)\n",
    "\n",
    "- You cannot just read off the values of coefficients because different attributes have different magnitudes of numbers e.g. the engine-power attribute has a largest value of 200000 but the compression-ratio attribute has a maximum value of 23. This means to \"move\" the compression-ratio attribute requires a much larger coefficient than to \"move\" the engine-power attribute. \n",
    "- To solve this issue we need to normalize the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "# Extract the attributes from the target\n",
    "auto_numeric_attr = auto_numeric.drop(columns=['price'])\n",
    "\n",
    "# Normalise all the attributes\n",
    "norm_auto_numeric = (auto_numeric_attr-auto_numeric_attr.mean())/auto_numeric_attr.std()\n",
    "\n",
    "# Fit the the model to the new normalised data\n",
    "mvlr.fit(norm_auto_numeric, auto_numeric['price'])\n",
    "\n",
    "# Extract the coefficients from the model\n",
    "coeff_series = {'attr': norm_auto_numeric.columns, 'coeff': mvlr.coef_}\n",
    "coeffs = pd.DataFrame(data=coeff_series)\n",
    "\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now order the attributes by the coefficiencts absolute value\n",
    "coeffs['abs'] = abs(coeffs['coeff'])\n",
    "coeffs.sort_values(by='abs', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) \n",
    "From the above dataframe we can see that the 3 most important attributes are:\n",
    "\n",
    "1. engine-size\n",
    "2. highway-mpg\n",
    "3. width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.5 --- (LEVEL 11) --- [10 marks] ==========\n",
    "\n",
    "In the lectures we discussed another form of extension to the basic linear-regression model: the introduction of basis functions. This method attempts to capture non-linearities in the input-output mapping.\n",
    "\n",
    "1. [Text] How would you choose the features to test higher-orders on? And how would you choose the best polynomial order for these features?\n",
    "1. [Code] Load the csv file `train_auto_nonlinear.csv` into a new dataframe (this is a standard version of the transformed data-set from [Question 3.3](#question_3_3)). Add a second-order basis to the two attributes `length` and `engine-power` and train a new LinearRegression model. Report the $R^2$ and RMSE performance.\n",
    "1. [Text] Comment on the result in relation to those in [Question 3.3](#question_3_3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) \n",
    "\n",
    "- Visualising the data is the best option for choosing which features to test higher orders on\n",
    "- Choosing the best polynomial order can be done several ways. One way would be to visualise the data and see if an obvious polynomial is apparent. Another option would be to use your validation set to tune the order of the polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "# Load data from csv\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'train_auto_nonlinear.csv')\n",
    "auto_nonlinear = pd.read_csv(data_path, delimiter = ',')\n",
    "auto_nonlinear.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the engine-power attribute\n",
    "ax = sns.scatterplot(auto_nonlinear['engine-power'], auto_nonlinear['price'])\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Engine-power')\n",
    "plt.title(\"Price vs. Engine Power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the length attribute\n",
    "ax = sns.scatterplot(auto_nonlinear['length'], auto_nonlinear['price'])\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Length')\n",
    "plt.title('Price vs. Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a second order basis to the engine-power and length attributes\n",
    "auto_nonlinear['engine-power2'] = auto_nonlinear['engine-power']**2\n",
    "auto_nonlinear['length2'] = auto_nonlinear['length']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Linear Regression Model\n",
    "so_lr = LinearRegression()\n",
    "so_lr.fit(auto_nonlinear.drop(columns=['price']), auto_nonlinear['price'])\n",
    "\n",
    "# Predict the price\n",
    "price_pred = so_lr.predict(auto_nonlinear.drop(columns=['price']))\n",
    "\n",
    "\n",
    "r2 = r2_score(auto_nonlinear['price'], price_pred)\n",
    "mse = mean_squared_error(auto_nonlinear['price'], price_pred)\n",
    "print(\"Coefficient of Determination (R^2): \" + str(np.around(r2, decimals=4)))\n",
    "print(\"Root Mean Squared Error (RMSE): \" + str(np.around(mse, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) We can see that our model has achieved a higher coefficient of determination and a lower RMSE meaning that the model has done a better job at predicting the price."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
